{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8342282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from   torchvision import transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d1021f",
   "metadata": {},
   "source": [
    "##### 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eebf84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'data/FourWeather/'\n",
    "train_dir= os.path.join(base_dir,\"train\")\n",
    "test_dir = os.path.join(base_dir,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e477214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                  transforms.Resize((96, 96)),\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize(\n",
    "                      mean=[0.5, 0.5, 0.5],\n",
    "                      std =[0.5, 0.5, 0.5]\n",
    "                  )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0afeb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e71f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torchvision.datasets.ImageFolder(\n",
    "    os.path.join(base_dir,\"train\"),\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "test_ds  = torchvision.datasets.ImageFolder(\n",
    "    os.path.join(base_dir,\"test\"),\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_dl  = torch.utils.data.DataLoader(test_ds,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d0fd6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_id = train_ds.class_to_idx\n",
    "id_to_class = dict((v,k) for k,v in train_ds.class_to_idx.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c19895",
   "metadata": {},
   "source": [
    "##### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "928ea140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc1   = nn.Linear(64*10*10, 1024)\n",
    "        self.fc2   = nn.Linear(1024, 256)\n",
    "        self.fc3   = nn.Linear(256, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 10 * 10)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a20caf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model   = Net()\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n",
    "optim   = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs     = 10\n",
    "train_loss = []\n",
    "train_acc  = []\n",
    "test_loss  = []\n",
    "test_acc   = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5d204",
   "metadata": {},
   "source": [
    "##### 定义fit函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2b0913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, model, trainloader, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    for x, y in trainloader:\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            correct += (y_pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            running_loss += loss.item()\n",
    "    epoch_loss = running_loss / len(trainloader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "        \n",
    "        \n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    test_running_loss = 0 \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            if torch.cuda.is_available():\n",
    "                x, y = x.to('cuda'), y.to('cuda')\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            test_correct += (y_pred == y).sum().item()\n",
    "            test_total += y.size(0)\n",
    "            test_running_loss += loss.item()\n",
    "    \n",
    "    epoch_test_loss = test_running_loss / len(testloader.dataset)\n",
    "    epoch_test_acc = test_correct / test_total\n",
    "    \n",
    "        \n",
    "    print('epoch: ', epoch, \n",
    "          'loss： ', round(epoch_loss, 3),\n",
    "          'accuracy:', round(epoch_acc, 3),\n",
    "          'test_loss： ', round(epoch_test_loss, 3),\n",
    "          'test_accuracy:', round(epoch_test_acc, 3)\n",
    "             )\n",
    "        \n",
    "    return epoch_loss, epoch_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25653427",
   "metadata": {},
   "source": [
    "##### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b490f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss：  0.1 accuracy: 0.639 test_loss：  0.084 test_accuracy: 0.738\n",
      "epoch:  1 loss：  0.064 accuracy: 0.79 test_loss：  0.08 test_accuracy: 0.8\n",
      "epoch:  2 loss：  0.057 accuracy: 0.828 test_loss：  0.07 test_accuracy: 0.818\n",
      "epoch:  3 loss：  0.044 accuracy: 0.858 test_loss：  0.061 test_accuracy: 0.884\n",
      "epoch:  4 loss：  0.042 accuracy: 0.88 test_loss：  0.078 test_accuracy: 0.836\n",
      "epoch:  5 loss：  0.036 accuracy: 0.9 test_loss：  0.088 test_accuracy: 0.831\n",
      "epoch:  6 loss：  0.031 accuracy: 0.901 test_loss：  0.074 test_accuracy: 0.898\n",
      "epoch:  7 loss：  0.027 accuracy: 0.914 test_loss：  0.081 test_accuracy: 0.871\n",
      "epoch:  8 loss：  0.02 accuracy: 0.937 test_loss：  0.078 test_accuracy: 0.858\n",
      "epoch:  9 loss：  0.017 accuracy: 0.942 test_loss：  0.085 test_accuracy: 0.884\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, epoch_test_loss, epoch_test_acc = fit(epoch,model,train_dl,test_dl)\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_acc.append(epoch_acc)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    test_acc.append(epoch_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c941cf",
   "metadata": {},
   "source": [
    "#### 模型的保存  (本质 : 保存训练好的模型的参数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "546a64e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[ 8.9591e-02,  9.4120e-02, -2.9476e-02],\n",
       "                        [ 1.3185e-01,  9.4362e-02,  2.0382e-02],\n",
       "                        [ 1.9112e-01,  2.1662e-01,  1.2812e-01]],\n",
       "              \n",
       "                       [[ 1.4434e-01, -7.4186e-02,  9.6240e-03],\n",
       "                        [-9.4958e-04,  8.4399e-03, -1.4463e-01],\n",
       "                        [-7.1932e-02, -1.6459e-01,  1.7691e-02]],\n",
       "              \n",
       "                       [[-1.6908e-01, -5.5856e-02, -1.1313e-01],\n",
       "                        [ 9.3552e-02, -1.1250e-01,  2.9621e-02],\n",
       "                        [ 1.5981e-01,  1.8239e-02,  1.0484e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8685e-03, -1.6254e-01, -2.4681e-02],\n",
       "                        [ 4.0850e-02, -1.5338e-01, -6.6552e-02],\n",
       "                        [ 1.7566e-01,  2.0099e-01, -9.4423e-03]],\n",
       "              \n",
       "                       [[-1.9084e-01, -1.2496e-01,  4.7322e-02],\n",
       "                        [-1.5655e-02, -1.4825e-01,  9.2427e-02],\n",
       "                        [ 3.2336e-02,  2.2077e-01,  1.2537e-01]],\n",
       "              \n",
       "                       [[-9.1824e-02, -1.6963e-02, -1.0606e-01],\n",
       "                        [ 4.7299e-02, -8.9393e-02, -7.7140e-02],\n",
       "                        [ 1.0284e-01,  1.0607e-01,  1.5508e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7917e-01, -9.4539e-02, -1.2090e-01],\n",
       "                        [ 2.0118e-02, -6.4211e-02,  3.9295e-02],\n",
       "                        [-1.5988e-01,  8.5841e-02, -1.8214e-01]],\n",
       "              \n",
       "                       [[ 9.1738e-02,  1.5553e-01, -1.0842e-01],\n",
       "                        [ 2.3170e-05, -6.2293e-02,  1.4287e-01],\n",
       "                        [-1.1109e-02,  2.4444e-01, -7.4085e-02]],\n",
       "              \n",
       "                       [[-3.4803e-02, -1.0039e-01, -7.0669e-02],\n",
       "                        [-1.6851e-01,  5.9842e-02,  1.1788e-01],\n",
       "                        [-4.4327e-02,  8.0115e-02,  6.8164e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5083e-01,  1.1994e-01, -4.2809e-02],\n",
       "                        [ 4.1268e-02,  4.1795e-02,  2.0024e-01],\n",
       "                        [-1.1398e-01,  1.8346e-01,  9.2085e-03]],\n",
       "              \n",
       "                       [[-6.9095e-02, -1.5391e-01, -1.0274e-01],\n",
       "                        [-9.8277e-02,  8.6632e-02,  1.0779e-01],\n",
       "                        [-1.9444e-01, -1.6362e-01,  1.4226e-01]],\n",
       "              \n",
       "                       [[-2.0274e-01,  1.3601e-01,  1.1015e-01],\n",
       "                        [-4.7217e-02, -7.0954e-02,  1.4752e-01],\n",
       "                        [-1.9178e-01,  8.5242e-02,  1.5847e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5390e-01,  7.3950e-02,  5.2069e-02],\n",
       "                        [ 1.3437e-01,  1.8898e-01, -5.4107e-02],\n",
       "                        [ 1.3585e-01,  3.1341e-02,  1.6722e-02]],\n",
       "              \n",
       "                       [[-1.0307e-01,  3.3048e-02, -9.9449e-02],\n",
       "                        [ 6.6989e-02, -1.5520e-01, -1.5970e-01],\n",
       "                        [-1.0620e-01, -9.0420e-02,  1.0101e-01]],\n",
       "              \n",
       "                       [[ 8.5081e-02, -7.6720e-02, -1.2796e-01],\n",
       "                        [-3.7939e-02,  1.1289e-01, -1.6175e-01],\n",
       "                        [ 8.6586e-02, -5.0545e-03,  9.6703e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.4325e-02, -1.6775e-01,  2.6560e-02],\n",
       "                        [ 1.5762e-01, -1.2648e-01,  7.1913e-02],\n",
       "                        [-8.6777e-02,  5.0066e-04, -1.2432e-01]],\n",
       "              \n",
       "                       [[ 6.1105e-02, -1.0790e-01,  3.1755e-02],\n",
       "                        [-6.8565e-02, -1.1297e-01,  8.5858e-02],\n",
       "                        [-1.7875e-02,  5.0815e-02,  4.1506e-02]],\n",
       "              \n",
       "                       [[ 4.9830e-02, -2.1268e-02,  1.8994e-01],\n",
       "                        [-5.5420e-02,  8.1938e-02, -2.8297e-02],\n",
       "                        [ 5.5721e-02,  1.2368e-01,  2.1889e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4107e-01,  2.1553e-03, -4.5377e-02],\n",
       "                        [ 4.1387e-02, -2.1313e-01, -1.1489e-01],\n",
       "                        [-1.4185e-01, -1.6413e-02,  3.2781e-02]],\n",
       "              \n",
       "                       [[-1.5753e-01, -1.3539e-01, -1.4198e-01],\n",
       "                        [-4.3770e-02,  2.0521e-02, -1.5110e-01],\n",
       "                        [ 5.5805e-04, -1.4438e-02, -3.7241e-03]],\n",
       "              \n",
       "                       [[ 5.2936e-02,  1.7610e-01, -1.7510e-01],\n",
       "                        [ 7.7193e-02, -1.3064e-01,  3.6034e-03],\n",
       "                        [-8.6149e-02, -1.7589e-01,  1.4900e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.5877e-02, -6.6476e-02,  8.5815e-02],\n",
       "                        [-1.8552e-01, -1.1574e-01,  1.6155e-01],\n",
       "                        [ 6.3106e-02,  5.8504e-02,  1.7354e-02]],\n",
       "              \n",
       "                       [[-2.6569e-02, -3.3635e-02,  7.5181e-02],\n",
       "                        [-5.0655e-02,  1.7370e-01,  6.2446e-02],\n",
       "                        [ 1.9840e-02,  2.6418e-02,  4.1561e-02]],\n",
       "              \n",
       "                       [[ 2.0980e-01, -6.8089e-02, -1.1468e-01],\n",
       "                        [ 1.0190e-01, -7.1466e-02,  1.8993e-01],\n",
       "                        [-7.9673e-02,  5.3045e-02,  1.6841e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2911e-02, -1.3181e-01, -2.0419e-01],\n",
       "                        [ 8.2062e-02, -1.3003e-01, -1.8304e-02],\n",
       "                        [ 1.3932e-03,  1.3383e-01,  1.2497e-01]],\n",
       "              \n",
       "                       [[ 1.5496e-01, -1.5185e-01, -5.0316e-02],\n",
       "                        [ 5.0534e-02, -9.8793e-02,  2.7843e-02],\n",
       "                        [-5.7039e-02,  8.9489e-03, -5.9042e-02]],\n",
       "              \n",
       "                       [[ 1.2952e-01, -9.6221e-02, -8.7662e-02],\n",
       "                        [ 4.6110e-02,  7.3748e-02,  1.7765e-01],\n",
       "                        [ 1.9983e-01,  9.1631e-02,  1.1974e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.8864e-02,  9.7200e-03,  1.7894e-01],\n",
       "                        [ 1.1141e-01,  1.5813e-01,  1.7976e-01],\n",
       "                        [-1.1811e-01, -1.5639e-01,  1.4509e-01]],\n",
       "              \n",
       "                       [[-1.2646e-01,  5.2808e-02,  1.0405e-01],\n",
       "                        [-4.7922e-03, -1.8017e-01, -1.3693e-01],\n",
       "                        [ 1.4056e-01,  3.1723e-02, -1.8534e-01]],\n",
       "              \n",
       "                       [[ 1.4216e-01,  4.4665e-02, -6.3277e-02],\n",
       "                        [-1.9713e-01, -6.9700e-02, -1.1180e-02],\n",
       "                        [-2.0930e-01,  1.0324e-01, -2.0186e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.7069e-02, -1.8212e-01, -5.5720e-02],\n",
       "                        [-6.5121e-02,  4.2873e-02,  2.0873e-01],\n",
       "                        [-1.3555e-01, -6.1962e-02, -1.6358e-02]],\n",
       "              \n",
       "                       [[-1.4970e-01, -1.3148e-01,  1.8557e-01],\n",
       "                        [ 1.4818e-01,  1.0084e-01, -1.6768e-01],\n",
       "                        [-1.1792e-01,  3.4924e-02,  1.1421e-02]],\n",
       "              \n",
       "                       [[-1.1176e-01, -1.3822e-01, -1.1447e-01],\n",
       "                        [ 5.7892e-02,  1.9287e-02,  2.1388e-02],\n",
       "                        [ 5.0147e-02,  1.1377e-02, -1.1743e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.9008e-02,  1.3112e-01, -8.0825e-02],\n",
       "                        [-1.5552e-01, -1.2010e-01,  9.4845e-02],\n",
       "                        [ 1.1296e-01, -1.5191e-01,  1.4683e-01]],\n",
       "              \n",
       "                       [[-1.6390e-01, -9.0910e-03, -8.0703e-02],\n",
       "                        [ 9.5300e-02, -1.0226e-01,  8.0869e-02],\n",
       "                        [-1.2705e-01, -1.1848e-01, -1.0838e-01]],\n",
       "              \n",
       "                       [[ 2.5559e-02,  8.8980e-02,  2.0911e-01],\n",
       "                        [-1.1746e-01, -1.4519e-01,  1.2346e-01],\n",
       "                        [-1.9166e-01, -1.5639e-01, -1.6601e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6094e-01,  1.6335e-01,  5.6220e-02],\n",
       "                        [ 1.8215e-01, -1.0292e-01,  2.2073e-01],\n",
       "                        [ 1.9456e-01, -5.3669e-02, -1.5109e-01]],\n",
       "              \n",
       "                       [[-1.6274e-01, -7.4459e-02,  2.0705e-02],\n",
       "                        [-1.7535e-01,  2.5792e-02,  1.1986e-01],\n",
       "                        [-1.4766e-01, -7.4420e-02,  2.5436e-02]],\n",
       "              \n",
       "                       [[-1.7550e-01,  1.2390e-01,  1.0209e-01],\n",
       "                        [-1.2081e-01, -9.8439e-03,  2.0170e-02],\n",
       "                        [-1.7798e-01, -1.0115e-01, -9.4349e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2100e-01, -6.8823e-02, -6.7129e-02],\n",
       "                        [-6.9499e-02, -1.9795e-01,  1.9744e-01],\n",
       "                        [ 1.7747e-01, -1.1360e-01,  1.3491e-01]],\n",
       "              \n",
       "                       [[-1.2303e-01, -1.2899e-01, -7.6490e-02],\n",
       "                        [-1.0427e-01,  1.1618e-01,  6.7352e-02],\n",
       "                        [ 1.7910e-01, -7.2333e-02,  1.6708e-01]],\n",
       "              \n",
       "                       [[ 1.3999e-01,  1.4780e-01,  5.3532e-02],\n",
       "                        [-1.1143e-01, -8.4072e-02, -9.5881e-03],\n",
       "                        [ 1.1443e-01, -1.9555e-01, -1.2990e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.8452e-02, -1.0285e-01, -1.1004e-01],\n",
       "                        [-6.6882e-02,  1.3093e-01,  7.1370e-02],\n",
       "                        [-9.5685e-02,  1.5694e-01,  4.9808e-02]],\n",
       "              \n",
       "                       [[ 3.7237e-02,  2.3256e-01, -1.1594e-01],\n",
       "                        [ 5.2732e-02, -1.1639e-01,  8.6842e-02],\n",
       "                        [ 4.3698e-02,  2.1582e-01,  4.3935e-03]],\n",
       "              \n",
       "                       [[-3.1270e-02, -6.8960e-02, -6.0028e-02],\n",
       "                        [-1.1399e-01, -1.0261e-01, -1.6947e-01],\n",
       "                        [ 1.0445e-01, -3.1109e-02,  1.1548e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9494e-02,  1.0874e-01,  1.5391e-01],\n",
       "                        [-1.7161e-01,  1.1872e-02, -5.1562e-02],\n",
       "                        [-1.4149e-01,  1.5096e-01, -1.8347e-01]],\n",
       "              \n",
       "                       [[ 9.1079e-02,  1.9228e-01, -4.5614e-02],\n",
       "                        [ 1.4299e-01, -1.2419e-01, -2.3257e-02],\n",
       "                        [ 1.0938e-01, -6.6078e-02, -2.3805e-02]],\n",
       "              \n",
       "                       [[ 1.2215e-01,  1.7351e-01, -5.7249e-02],\n",
       "                        [ 1.5248e-02,  6.3915e-02, -5.5033e-04],\n",
       "                        [-2.1153e-02, -4.1168e-02,  3.0345e-02]]]], device='cuda:0')),\n",
       "             ('conv1.bias',\n",
       "              tensor([-0.0194, -0.1900, -0.0047,  0.1061, -0.1089, -0.0553, -0.1930, -0.1353,\n",
       "                       0.0635, -0.1863,  0.0750, -0.1506, -0.1471,  0.0173,  0.0501, -0.1492],\n",
       "                     device='cuda:0')),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[-0.0959, -0.1317, -0.0939],\n",
       "                        [-0.0944, -0.1084, -0.0872],\n",
       "                        [-0.1200, -0.1122, -0.1026]],\n",
       "              \n",
       "                       [[ 0.0589, -0.0033,  0.0787],\n",
       "                        [-0.0653, -0.0211, -0.0167],\n",
       "                        [-0.1107, -0.0707, -0.0058]],\n",
       "              \n",
       "                       [[ 0.0170, -0.0009,  0.1068],\n",
       "                        [ 0.0733,  0.0590,  0.0502],\n",
       "                        [ 0.0667,  0.0315,  0.0846]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0603,  0.0793,  0.0079],\n",
       "                        [ 0.1029,  0.0727,  0.0353],\n",
       "                        [-0.0021, -0.0020, -0.0463]],\n",
       "              \n",
       "                       [[-0.0995, -0.0035,  0.0691],\n",
       "                        [ 0.0030,  0.0439, -0.0807],\n",
       "                        [-0.0315, -0.0227,  0.0545]],\n",
       "              \n",
       "                       [[-0.0163, -0.0268,  0.0061],\n",
       "                        [ 0.0555,  0.0703, -0.0507],\n",
       "                        [ 0.0577,  0.0928,  0.0398]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0393,  0.0592,  0.0256],\n",
       "                        [-0.0649,  0.0150,  0.0534],\n",
       "                        [-0.0493, -0.1205,  0.0206]],\n",
       "              \n",
       "                       [[ 0.0229, -0.0260,  0.0362],\n",
       "                        [-0.0545,  0.0588,  0.0297],\n",
       "                        [ 0.0197,  0.0341,  0.0788]],\n",
       "              \n",
       "                       [[ 0.0394, -0.0565, -0.0541],\n",
       "                        [-0.0309,  0.0370,  0.0324],\n",
       "                        [-0.0677, -0.0582,  0.0170]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0639, -0.0501, -0.0781],\n",
       "                        [ 0.0708,  0.0116,  0.0169],\n",
       "                        [ 0.0150,  0.0832, -0.0109]],\n",
       "              \n",
       "                       [[-0.0674,  0.0202, -0.0717],\n",
       "                        [-0.0759,  0.0044, -0.0947],\n",
       "                        [ 0.0190, -0.0531, -0.0522]],\n",
       "              \n",
       "                       [[-0.0135, -0.0578,  0.0192],\n",
       "                        [-0.0109, -0.0567,  0.0853],\n",
       "                        [ 0.1139,  0.0912,  0.0236]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0918, -0.0264, -0.0010],\n",
       "                        [-0.0750, -0.0700, -0.0431],\n",
       "                        [-0.0596,  0.0079, -0.0149]],\n",
       "              \n",
       "                       [[-0.0090, -0.0164,  0.0073],\n",
       "                        [-0.1608, -0.0806, -0.0660],\n",
       "                        [-0.1194, -0.1241, -0.1481]],\n",
       "              \n",
       "                       [[ 0.1204,  0.1564,  0.0327],\n",
       "                        [ 0.1318,  0.0531,  0.1730],\n",
       "                        [ 0.0398,  0.2127,  0.1159]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1080,  0.0991,  0.0096],\n",
       "                        [ 0.1403,  0.0452,  0.0073],\n",
       "                        [ 0.1407,  0.0546,  0.0834]],\n",
       "              \n",
       "                       [[ 0.1081,  0.0188, -0.0077],\n",
       "                        [ 0.1194,  0.0599,  0.0900],\n",
       "                        [ 0.1127,  0.0347,  0.0797]],\n",
       "              \n",
       "                       [[-0.0592, -0.0225, -0.0264],\n",
       "                        [-0.0070,  0.0642,  0.1201],\n",
       "                        [-0.0459, -0.0464,  0.0204]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0422,  0.0551,  0.0123],\n",
       "                        [ 0.0574,  0.0421, -0.0115],\n",
       "                        [ 0.0720,  0.0428,  0.0992]],\n",
       "              \n",
       "                       [[ 0.0184,  0.0428, -0.0125],\n",
       "                        [-0.0472,  0.0599,  0.0103],\n",
       "                        [ 0.0610, -0.0729, -0.0169]],\n",
       "              \n",
       "                       [[-0.0246, -0.0612, -0.1129],\n",
       "                        [-0.0928, -0.0678, -0.1013],\n",
       "                        [-0.1059, -0.0862, -0.0280]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0814, -0.0296,  0.0231],\n",
       "                        [-0.0312,  0.0408,  0.0347],\n",
       "                        [-0.0766,  0.0137, -0.0439]],\n",
       "              \n",
       "                       [[ 0.0552, -0.0685,  0.0795],\n",
       "                        [ 0.0127,  0.0853, -0.0248],\n",
       "                        [-0.0436,  0.0771,  0.0115]],\n",
       "              \n",
       "                       [[-0.0076,  0.0596, -0.0202],\n",
       "                        [ 0.0336, -0.0428, -0.0904],\n",
       "                        [ 0.0255, -0.0132, -0.0713]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0952,  0.0490,  0.0440],\n",
       "                        [ 0.0017, -0.0521, -0.0193],\n",
       "                        [-0.0316, -0.0068, -0.1270]],\n",
       "              \n",
       "                       [[-0.0922,  0.0559, -0.0124],\n",
       "                        [ 0.0433,  0.0476, -0.1032],\n",
       "                        [ 0.0408, -0.0260, -0.0714]],\n",
       "              \n",
       "                       [[-0.0309, -0.0239,  0.0122],\n",
       "                        [ 0.0504, -0.0298, -0.0386],\n",
       "                        [ 0.0671, -0.0016,  0.0121]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0047, -0.0791, -0.0331],\n",
       "                        [-0.0813, -0.0402, -0.0379],\n",
       "                        [-0.1177, -0.0384, -0.0838]],\n",
       "              \n",
       "                       [[-0.0754, -0.0711,  0.0253],\n",
       "                        [-0.1141, -0.0017,  0.0292],\n",
       "                        [ 0.0312, -0.1008, -0.0695]],\n",
       "              \n",
       "                       [[-0.0060,  0.0232,  0.0225],\n",
       "                        [ 0.0533,  0.0039,  0.0325],\n",
       "                        [-0.0931, -0.0872, -0.0770]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0608,  0.0379,  0.0750],\n",
       "                        [ 0.0997,  0.0355,  0.0469],\n",
       "                        [ 0.1089,  0.0892, -0.0529]],\n",
       "              \n",
       "                       [[ 0.0828,  0.1275,  0.0846],\n",
       "                        [ 0.0457,  0.0324,  0.1118],\n",
       "                        [ 0.0464,  0.0436, -0.0562]],\n",
       "              \n",
       "                       [[ 0.0515, -0.0562, -0.0690],\n",
       "                        [-0.0855, -0.0524, -0.0980],\n",
       "                        [ 0.0225, -0.0239, -0.0511]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0082,  0.0276,  0.0120],\n",
       "                        [-0.0263,  0.0549, -0.0751],\n",
       "                        [ 0.0313,  0.0068,  0.0131]],\n",
       "              \n",
       "                       [[ 0.0911,  0.0665,  0.0424],\n",
       "                        [ 0.0341,  0.0963, -0.0394],\n",
       "                        [ 0.0776, -0.0497,  0.0232]],\n",
       "              \n",
       "                       [[ 0.0207,  0.0329, -0.0266],\n",
       "                        [-0.0580,  0.0775, -0.0134],\n",
       "                        [-0.0578,  0.0059, -0.0458]]]], device='cuda:0')),\n",
       "             ('conv2.bias',\n",
       "              tensor([-0.0588, -0.0247, -0.0174, -0.0771, -0.0425,  0.0550, -0.0164,  0.0715,\n",
       "                      -0.0509,  0.0573,  0.0555,  0.0215, -0.0530,  0.0183, -0.0621, -0.0097,\n",
       "                       0.0816,  0.0644, -0.0391, -0.0481,  0.0727, -0.0377, -0.0478, -0.0090,\n",
       "                      -0.0475,  0.0496, -0.0758, -0.0115, -0.0177,  0.0354,  0.0790,  0.0114],\n",
       "                     device='cuda:0')),\n",
       "             ('conv3.weight',\n",
       "              tensor([[[[-0.0028, -0.0102, -0.0594],\n",
       "                        [ 0.0390, -0.0213, -0.0507],\n",
       "                        [-0.0087,  0.0305, -0.0085]],\n",
       "              \n",
       "                       [[-0.0370,  0.0377, -0.0213],\n",
       "                        [-0.0303, -0.0142,  0.0031],\n",
       "                        [-0.0385,  0.0506, -0.0245]],\n",
       "              \n",
       "                       [[ 0.1410,  0.1002,  0.0351],\n",
       "                        [ 0.0542,  0.1264,  0.1013],\n",
       "                        [ 0.0824,  0.0632,  0.0350]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0300, -0.0835,  0.0254],\n",
       "                        [-0.0397,  0.0173, -0.0090],\n",
       "                        [-0.0105, -0.0225,  0.0271]],\n",
       "              \n",
       "                       [[-0.0174,  0.0448,  0.0431],\n",
       "                        [ 0.0518,  0.0078, -0.0286],\n",
       "                        [-0.0526, -0.0578,  0.0260]],\n",
       "              \n",
       "                       [[-0.0143, -0.0537, -0.0461],\n",
       "                        [-0.0206,  0.0128, -0.0007],\n",
       "                        [ 0.0371, -0.0182, -0.0264]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0245, -0.0753, -0.0457],\n",
       "                        [ 0.0013, -0.0053, -0.0039],\n",
       "                        [-0.0594, -0.0121,  0.0274]],\n",
       "              \n",
       "                       [[ 0.0843,  0.0482,  0.0113],\n",
       "                        [ 0.0495,  0.0279,  0.0388],\n",
       "                        [-0.0656, -0.0263, -0.0090]],\n",
       "              \n",
       "                       [[ 0.0074,  0.0152, -0.0093],\n",
       "                        [ 0.0280,  0.0058,  0.0220],\n",
       "                        [ 0.0295,  0.0431,  0.0395]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0349,  0.0134, -0.0191],\n",
       "                        [ 0.0276,  0.0147, -0.0366],\n",
       "                        [-0.0535,  0.0561,  0.0443]],\n",
       "              \n",
       "                       [[-0.0533, -0.0731,  0.0344],\n",
       "                        [-0.0287, -0.0726, -0.0361],\n",
       "                        [ 0.0416,  0.0435, -0.0544]],\n",
       "              \n",
       "                       [[-0.0417, -0.0305, -0.0292],\n",
       "                        [-0.0033, -0.0520,  0.0405],\n",
       "                        [ 0.0027, -0.0215,  0.0141]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0582, -0.0573, -0.0009],\n",
       "                        [-0.0610, -0.0008,  0.0329],\n",
       "                        [-0.0344,  0.0459, -0.0421]],\n",
       "              \n",
       "                       [[-0.0377,  0.0103, -0.0014],\n",
       "                        [ 0.0079,  0.0459,  0.0180],\n",
       "                        [-0.0455,  0.0096,  0.0662]],\n",
       "              \n",
       "                       [[-0.0501, -0.0275, -0.0491],\n",
       "                        [ 0.0021,  0.0278, -0.0423],\n",
       "                        [-0.0076, -0.0730, -0.0787]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0670,  0.0189,  0.0101],\n",
       "                        [ 0.0711,  0.0758,  0.0796],\n",
       "                        [ 0.0675,  0.0152,  0.0433]],\n",
       "              \n",
       "                       [[ 0.0229,  0.0036,  0.0342],\n",
       "                        [-0.0324,  0.0033, -0.0023],\n",
       "                        [-0.0015, -0.0415,  0.0220]],\n",
       "              \n",
       "                       [[ 0.0154,  0.0226,  0.0662],\n",
       "                        [ 0.0015, -0.0089,  0.0660],\n",
       "                        [ 0.0261, -0.0147,  0.0493]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0504,  0.0363,  0.0310],\n",
       "                        [-0.0110, -0.0059, -0.0069],\n",
       "                        [ 0.0321,  0.0015, -0.0214]],\n",
       "              \n",
       "                       [[ 0.0464, -0.0696, -0.0194],\n",
       "                        [-0.0469,  0.0076,  0.0119],\n",
       "                        [-0.0276, -0.0183, -0.0899]],\n",
       "              \n",
       "                       [[ 0.1447,  0.1038,  0.1316],\n",
       "                        [ 0.1009,  0.1180,  0.0390],\n",
       "                        [ 0.1107,  0.1209,  0.1237]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0434,  0.0099, -0.0149],\n",
       "                        [-0.0585,  0.0032, -0.0526],\n",
       "                        [-0.0647,  0.0382, -0.0696]],\n",
       "              \n",
       "                       [[-0.0540,  0.0405, -0.0293],\n",
       "                        [ 0.0105, -0.0092,  0.0089],\n",
       "                        [-0.0245, -0.0055, -0.0535]],\n",
       "              \n",
       "                       [[-0.0190,  0.0509, -0.0230],\n",
       "                        [-0.0183,  0.0331,  0.0519],\n",
       "                        [ 0.0483,  0.0144, -0.0234]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0730, -0.0621, -0.0152],\n",
       "                        [-0.0597, -0.0003,  0.0302],\n",
       "                        [-0.0203,  0.0317,  0.0916]],\n",
       "              \n",
       "                       [[-0.0277,  0.0468,  0.0286],\n",
       "                        [ 0.0924, -0.0117,  0.0839],\n",
       "                        [ 0.0588,  0.1013,  0.0472]],\n",
       "              \n",
       "                       [[ 0.0034,  0.0163,  0.1120],\n",
       "                        [-0.0411, -0.0319,  0.0598],\n",
       "                        [ 0.0225, -0.0366, -0.0170]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0148, -0.0666,  0.0188],\n",
       "                        [-0.0422,  0.0217, -0.0775],\n",
       "                        [-0.0532, -0.0250, -0.0717]],\n",
       "              \n",
       "                       [[ 0.0421,  0.0683,  0.0291],\n",
       "                        [-0.0307, -0.0053, -0.0524],\n",
       "                        [-0.0083,  0.0277, -0.0755]],\n",
       "              \n",
       "                       [[ 0.0460, -0.0561, -0.0061],\n",
       "                        [-0.0494, -0.0515, -0.0188],\n",
       "                        [-0.0123, -0.0511, -0.0131]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0269, -0.0071, -0.0193],\n",
       "                        [ 0.0421,  0.0013,  0.0650],\n",
       "                        [ 0.0507, -0.0278, -0.0166]],\n",
       "              \n",
       "                       [[-0.0029, -0.0012, -0.0260],\n",
       "                        [ 0.0786,  0.0629,  0.0367],\n",
       "                        [ 0.0793,  0.0362,  0.0776]],\n",
       "              \n",
       "                       [[-0.0491,  0.0275, -0.0553],\n",
       "                        [ 0.0339, -0.0186, -0.0295],\n",
       "                        [-0.0101,  0.0503,  0.0467]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0200, -0.0210, -0.0440],\n",
       "                        [ 0.0670,  0.0389, -0.0526],\n",
       "                        [-0.0166, -0.0257, -0.0309]],\n",
       "              \n",
       "                       [[-0.0410,  0.0542,  0.0338],\n",
       "                        [-0.0150, -0.0332,  0.0316],\n",
       "                        [ 0.0508,  0.0029, -0.0505]],\n",
       "              \n",
       "                       [[ 0.0335, -0.0139, -0.0412],\n",
       "                        [ 0.0469, -0.0211, -0.0468],\n",
       "                        [ 0.0534,  0.0112, -0.0673]]]], device='cuda:0')),\n",
       "             ('conv3.bias',\n",
       "              tensor([ 0.0451, -0.0661, -0.0177,  0.0569, -0.0505,  0.0617,  0.0303, -0.0447,\n",
       "                      -0.0516, -0.0226, -0.0254, -0.0411, -0.0238, -0.0164,  0.0235, -0.0048,\n",
       "                      -0.0237, -0.0009,  0.0025,  0.0247, -0.0243, -0.0593, -0.0594, -0.0519,\n",
       "                      -0.0645,  0.0163, -0.0624,  0.0030, -0.0809,  0.0046, -0.0120, -0.0221,\n",
       "                       0.0193, -0.0676, -0.0236,  0.0332, -0.0266, -0.0695, -0.0507, -0.0761,\n",
       "                       0.0052, -0.0640, -0.0659,  0.0099, -0.0256, -0.0403, -0.0082,  0.0360,\n",
       "                      -0.0242,  0.0013, -0.0441, -0.0270, -0.0470, -0.0027,  0.0740,  0.0124,\n",
       "                      -0.0393, -0.0658, -0.0879, -0.0314, -0.0413, -0.0253, -0.0451, -0.0450],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0038,  0.0042, -0.0086,  ...,  0.0011, -0.0103, -0.0054],\n",
       "                      [-0.0340, -0.0172, -0.0283,  ..., -0.0185, -0.0154, -0.0006],\n",
       "                      [-0.0270, -0.0152, -0.0102,  ...,  0.0014,  0.0060,  0.0066],\n",
       "                      ...,\n",
       "                      [-0.0133,  0.0033,  0.0018,  ..., -0.0101, -0.0137,  0.0058],\n",
       "                      [-0.0072, -0.0011,  0.0045,  ...,  0.0040, -0.0114, -0.0163],\n",
       "                      [-0.0447, -0.0547, -0.0514,  ..., -0.0245, -0.0159, -0.0204]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.0166, -0.0253, -0.0322,  ...,  0.0017, -0.0176, -0.0338],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0271, -0.0194,  0.0051,  ...,  0.0208, -0.0055, -0.0136],\n",
       "                      [ 0.0286, -0.0013,  0.0024,  ...,  0.0357, -0.0180,  0.0343],\n",
       "                      [-0.0235, -0.0091,  0.0143,  ..., -0.0014, -0.0147, -0.0092],\n",
       "                      ...,\n",
       "                      [ 0.0079,  0.0279,  0.0183,  ...,  0.0223,  0.0010, -0.0212],\n",
       "                      [ 0.0328, -0.0048,  0.0194,  ...,  0.0080,  0.0393, -0.0109],\n",
       "                      [ 0.0122, -0.0030, -0.0249,  ..., -0.0152, -0.0339,  0.0229]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 5.8123e-02,  1.6453e-02, -4.1579e-02,  5.9701e-02, -9.1249e-03,\n",
       "                      -9.3796e-03,  5.0681e-02, -2.7719e-02,  2.1918e-02, -2.4835e-02,\n",
       "                       1.0787e-02, -2.6207e-02,  2.0998e-02,  2.8983e-02, -4.5135e-03,\n",
       "                      -4.6612e-02,  5.4727e-02,  2.0900e-02, -2.3218e-02, -1.7790e-02,\n",
       "                       7.2813e-02,  1.0784e-01,  1.2224e-02,  2.1127e-02, -3.1078e-04,\n",
       "                      -1.1192e-02, -6.4736e-03,  1.0795e-01, -1.4571e-02,  1.2951e-02,\n",
       "                      -3.2835e-02,  7.1786e-02, -3.2214e-02,  4.2344e-02, -1.7034e-02,\n",
       "                      -1.1943e-02, -2.7377e-02,  2.4077e-02, -1.4377e-02, -4.5179e-05,\n",
       "                       8.9477e-03, -1.9425e-02,  6.3024e-02,  2.1635e-02, -3.8892e-02,\n",
       "                       1.3284e-02,  2.9279e-02, -3.2507e-02,  1.1971e-04, -1.1944e-02,\n",
       "                      -2.0812e-02,  1.0994e-02, -1.6794e-02,  4.9239e-02,  2.5208e-02,\n",
       "                       5.1304e-03,  4.8737e-03,  2.9631e-02,  2.1743e-02,  3.4056e-02,\n",
       "                       2.8003e-02,  6.6106e-03, -7.5818e-03, -4.8141e-02, -6.3491e-03,\n",
       "                       6.5537e-03,  2.6062e-04,  6.1415e-03,  3.2637e-03, -2.2505e-02,\n",
       "                      -7.2066e-02,  6.9892e-02,  7.0741e-02, -1.1274e-03, -1.2166e-02,\n",
       "                      -3.1288e-02,  8.0419e-02,  7.0030e-03,  5.8618e-02, -2.1506e-02,\n",
       "                      -1.3618e-02, -3.9634e-02, -4.1493e-02, -3.1344e-05, -2.9281e-02,\n",
       "                       2.9920e-02, -9.3325e-03, -1.5960e-02, -1.9192e-02, -2.9328e-02,\n",
       "                       1.8573e-02, -4.2310e-02, -8.2499e-04,  8.8934e-02, -3.2323e-03,\n",
       "                      -3.6765e-02, -1.6203e-02,  1.7197e-02,  1.0255e-02,  7.2610e-02,\n",
       "                      -1.1086e-02, -1.0065e-02, -5.6163e-03,  1.4613e-02, -3.5651e-02,\n",
       "                      -9.4554e-03,  2.5815e-02, -5.2306e-03, -1.4820e-02, -2.3484e-02,\n",
       "                       6.7068e-03, -2.4901e-02, -9.2278e-03,  2.2430e-02,  3.0304e-02,\n",
       "                       1.5876e-02,  3.6470e-02, -3.5725e-02, -1.7289e-02, -2.3855e-02,\n",
       "                      -3.6733e-02, -7.8804e-03, -2.1463e-02,  1.2136e-02, -1.7299e-02,\n",
       "                       3.2200e-03,  2.1683e-02, -2.9498e-02,  3.4868e-02,  6.8142e-02,\n",
       "                      -4.0286e-02,  7.3611e-02,  2.3282e-02,  5.3374e-02, -2.3372e-03,\n",
       "                      -4.1799e-02,  3.8332e-02, -5.7413e-02,  6.6395e-02, -2.8237e-02,\n",
       "                       1.7427e-03,  2.1726e-02,  1.1099e-02,  2.1116e-02, -3.0288e-02,\n",
       "                      -1.5233e-02, -4.7273e-03,  6.0610e-03,  4.7333e-03, -3.7543e-02,\n",
       "                       3.7650e-02, -1.1270e-02,  4.3110e-02, -6.1122e-03, -8.1669e-04,\n",
       "                      -1.5501e-02,  1.1191e-02, -3.6537e-02, -1.0022e-02, -9.3708e-03,\n",
       "                       1.3932e-02,  1.2344e-02, -3.2174e-02, -1.2206e-02, -1.5487e-03,\n",
       "                      -3.6638e-02, -8.2995e-03, -2.0896e-02,  5.6719e-02,  2.0779e-02,\n",
       "                      -1.6657e-02,  1.3109e-02, -1.6181e-02,  4.7654e-03, -2.1065e-02,\n",
       "                      -1.2863e-02, -4.5455e-02,  4.1380e-02,  2.4727e-02,  7.4055e-02,\n",
       "                      -2.8796e-02, -1.8274e-02,  2.1421e-02,  6.2305e-04, -5.3488e-03,\n",
       "                       6.7142e-03,  6.8650e-03, -2.9907e-03, -2.2707e-02, -1.8006e-02,\n",
       "                      -2.8145e-02,  2.0233e-02, -1.6385e-02,  4.6827e-02, -1.7703e-02,\n",
       "                      -4.6723e-03, -7.6105e-03,  2.2709e-02, -2.3459e-02,  1.9828e-02,\n",
       "                       1.0614e-01, -4.8996e-02, -4.4836e-02, -3.9505e-02,  5.8188e-03,\n",
       "                      -9.1155e-03, -1.5405e-02,  1.8837e-02,  3.7692e-03, -5.9225e-04,\n",
       "                       2.0046e-03,  4.8061e-02,  5.2501e-02, -3.5907e-02, -1.9611e-02,\n",
       "                      -1.9295e-02, -1.4505e-02, -1.0799e-02,  1.1048e-02,  5.0325e-02,\n",
       "                      -5.5318e-04,  2.0637e-02, -1.0304e-02, -3.5186e-02,  1.8262e-02,\n",
       "                       2.3681e-03,  4.9733e-02, -3.7967e-02, -1.8284e-02, -1.6013e-02,\n",
       "                       4.7308e-02, -7.1298e-03, -2.1955e-02,  8.8608e-03, -5.1068e-02,\n",
       "                      -6.4813e-02,  2.3911e-02, -4.4989e-03,  5.8409e-02,  2.2973e-02,\n",
       "                      -5.0856e-02, -5.1387e-02, -1.5422e-02, -5.0614e-02,  8.0512e-02,\n",
       "                      -2.6926e-02, -6.8728e-03, -6.5032e-02,  3.2593e-02,  2.9556e-02,\n",
       "                       4.7239e-02, -3.3616e-02, -2.7369e-02, -6.7710e-03,  1.4444e-02,\n",
       "                      -1.8118e-02], device='cuda:0')),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 6.1514e-02, -1.0585e-02, -7.2185e-03,  ...,  1.3237e-02,\n",
       "                        4.7190e-02, -4.6006e-02],\n",
       "                      [ 1.1696e-02, -7.3643e-02, -5.4745e-02,  ...,  2.5743e-02,\n",
       "                       -1.9187e-03, -1.4653e-02],\n",
       "                      [-4.8617e-06, -6.2280e-03, -5.6582e-02,  ...,  2.5760e-02,\n",
       "                       -4.6509e-02,  5.7826e-02],\n",
       "                      [-1.1967e-01,  4.7447e-02,  2.3719e-02,  ..., -3.0022e-02,\n",
       "                        3.1138e-02,  2.3195e-02]], device='cuda:0')),\n",
       "             ('fc3.bias',\n",
       "              tensor([ 0.0525,  0.0754, -0.0614, -0.0267], device='cuda:0'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()                                  # 返回一个字典 将模型中可训练参数(权重)和权值返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c25a14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"my_model.pth\"                               # 习惯上将训练好的模型的权值保存到.pth文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88a51b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),PATH)                 # 将模型的权重保存到指定位置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ede27",
   "metadata": {},
   "source": [
    "##### 模型的加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "748a6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Net()                                   # 新建一个模型对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4329dda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_state_dict(torch.load(PATH))         # 在新模型上加载已有的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "224f35f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.884\n"
     ]
    }
   ],
   "source": [
    "#### 加载模型完毕后的测试\n",
    "test_correct      = 0\n",
    "test_total        = 0\n",
    "test_running_loss = 0 \n",
    "\n",
    "new_model         = new_model.to(\"cuda\")\n",
    "\n",
    "model.eval()                                        # 在测试的过程中必须要使用eval()模式继续进行\n",
    "with torch.no_grad():\n",
    "    for x, y in test_dl:\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "        y_pred = new_model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "        test_correct += (y_pred == y).sum().item()\n",
    "        test_total += y.size(0)\n",
    "        test_running_loss += loss.item()\n",
    "\n",
    "epoch_test_loss = test_running_loss / len(test_dl.dataset)\n",
    "epoch_test_acc = test_correct / test_total\n",
    "print(round(epoch_test_acc, 3))                     # 计算并输出模型在一个epoch之后在测试数据集上的准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec454991",
   "metadata": {},
   "source": [
    "##### 保存最优模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d223f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_wts = copy.deepcopy(model.state_dict())  # 使用深拷贝对当前模型权重进行保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64ef22d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc       = 0                                  # 存储当前模型最优准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd224b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss：  0.009 accuracy: 0.968 test_loss：  0.102 test_accuracy: 0.871\n",
      "epoch:  1 loss：  0.018 accuracy: 0.958 test_loss：  0.117 test_accuracy: 0.88\n",
      "epoch:  2 loss：  0.009 accuracy: 0.976 test_loss：  0.087 test_accuracy: 0.889\n",
      "epoch:  3 loss：  0.007 accuracy: 0.981 test_loss：  0.152 test_accuracy: 0.871\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, epoch_test_loss, epoch_test_acc = fit(epoch,model,train_dl,test_dl)\n",
    "    \n",
    "    \n",
    "    if epoch_test_acc  > best_acc:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict()) # 保存最优模型的参数\n",
    "        best_acc       = epoch_test_acc                    # 更新最新的正确率\n",
    "     \n",
    "    train_loss.append(epoch_loss)\n",
    "    train_acc.append(epoch_acc)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    test_acc.append(epoch_test_acc)\n",
    "model.load_state_dict(best_model_wts)                      # 将最优权重赋值给当前模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
