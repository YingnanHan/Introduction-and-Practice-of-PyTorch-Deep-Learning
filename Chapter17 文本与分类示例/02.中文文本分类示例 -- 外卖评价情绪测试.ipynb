{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f999d5",
   "metadata": {},
   "source": [
    "##### 导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13868650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from   matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e185385",
   "metadata": {},
   "source": [
    "##### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9396bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"waimai_10k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a594b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''自定义文本处理函数'''\n",
    "def pre_text(text):\n",
    "    text = text.replace('！','').replace('，','').replace('。','')\n",
    "    '''对文本直接做分词'''\n",
    "    return jieba.lcut(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc7d53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\20613\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.562 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "'''在data的review属性上使用pre_text方法'''\n",
    "data['review'] = data.review.apply(pre_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a0d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计不同的单词出现的次数\n",
    "word_count    = pd.value_counts(np.concatenate(data.review.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "744ebd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用布尔过滤将word_count中的出现次数较少的单词删去\n",
    "word_count    = word_count[word_count>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4611ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''对文本进行编码'''\n",
    "word_list     = list(word_count.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90931cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = dict((w,word_list.index(w)+1) for w in word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b029050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text          = data.review.apply(lambda t:[word_to_index.get(w,0) for w in t]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0bd1096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了进单处理 将textlen人为设置为20\n",
    "text_len = 20\n",
    "pad_text = [l + (text_len - len(l)) * [0] if len(l)<=text_len else l[:text_len] for l in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dffeeaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_text = np.array(pad_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65b1ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels   = data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "792613c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 切分数据集为测试&训练两部分 '''\n",
    "x_train,x_test,y_train,y_test = train_test_split(pad_text,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e04f89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self,text,label):\n",
    "        self.text_array = text\n",
    "        self.label_array= label\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        text = torch.LongTensor(self.text_array[index])\n",
    "        label= self.label_array[index]\n",
    "        return text,label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20a26a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds   = MyDataSet(x_train,y_train)\n",
    "test_ds    = MyDataSet(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1c0ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca2edf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl   = torch.utils.data.DataLoader(train_ds,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_dl    = torch.utils.data.DataLoader(test_ds ,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97645e23",
   "metadata": {},
   "source": [
    "##### 创建模型 并测试(基于LSTM模型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6daf623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "hidden_size   = 200\n",
    "max_word      = len(word_to_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0db3af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,max_word,embedding_dim):\n",
    "        super(Net,self).__init__()\n",
    "        self.em   = nn.Embedding(max_word,embedding_dim) #将max_word个单词编码到embedding_dim维向量中  batch*maxlen*100\n",
    "        self.rnn  = nn.LSTM(embedding_dim,\n",
    "                            hidden_size,\n",
    "                            num_layers=3,                #优化策略 RNN循环层堆叠\n",
    "                            dropout=0.5,\n",
    "                            bidirectional=True           #设置双向RNN\n",
    "                           )             \n",
    "        #self.fc1 = nn.Linear(hidden_size,128)\n",
    "        self.fc1  = nn.Linear(hidden_size*2,128)         #双向RNN的时候隐藏层会变成原来的两倍\n",
    "        self.fc2  = nn.Linear(128,2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x     = self.em(x)\n",
    "        r_o,_ = self.rnn(x)\n",
    "        r_o   = r_o[-1]\n",
    "        x     = F.dropout(F.relu(self.fc1(r_o)))\n",
    "        x     = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db47dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model      = Net(max_word, embedding_dim)\n",
    "model      = model.to(\"cuda\")\n",
    "loss_fn    = nn.CrossEntropyLoss()\n",
    "optimizer  = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs     = 30\n",
    "train_loss = []\n",
    "train_acc  = []\n",
    "test_loss  = []\n",
    "test_acc   = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "623a8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, model, trainloader, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for x, y in trainloader:\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.permute(1, 0)\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            correct += (y_pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            running_loss += loss.item()\n",
    "#    exp_lr_scheduler.step()\n",
    "    epoch_loss = running_loss / len(trainloader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "        \n",
    "        \n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    test_running_loss = 0 \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.permute(1, 0)\n",
    "                x, y = x.to('cuda'), y.to('cuda')\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            test_correct += (y_pred == y).sum().item()\n",
    "            test_total += y.size(0)\n",
    "            test_running_loss += loss.item()\n",
    "    \n",
    "    epoch_test_loss = test_running_loss / len(testloader.dataset)\n",
    "    epoch_test_acc = test_correct / test_total\n",
    "    \n",
    "        \n",
    "    print('epoch:\\t', epoch,'loss:\\t', round(epoch_loss, 3),'accuracy:\\t', round(epoch_acc, 3),'test_loss:\\t', round(epoch_test_loss, 3),'test_accuracy:\\t', round(epoch_test_acc, 3))\n",
    "        \n",
    "    return epoch_loss, epoch_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92d42395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:\t 0 loss:\t 0.015 accuracy:\t 0.789 test_loss:\t 0.011 test_accuracy:\t 0.863\n",
      "epoch:\t 1 loss:\t 0.01 accuracy:\t 0.888 test_loss:\t 0.011 test_accuracy:\t 0.879\n",
      "epoch:\t 2 loss:\t 0.009 accuracy:\t 0.903 test_loss:\t 0.01 test_accuracy:\t 0.876\n",
      "epoch:\t 3 loss:\t 0.008 accuracy:\t 0.912 test_loss:\t 0.012 test_accuracy:\t 0.877\n",
      "epoch:\t 4 loss:\t 0.008 accuracy:\t 0.917 test_loss:\t 0.01 test_accuracy:\t 0.881\n",
      "epoch:\t 5 loss:\t 0.007 accuracy:\t 0.925 test_loss:\t 0.011 test_accuracy:\t 0.883\n",
      "epoch:\t 6 loss:\t 0.007 accuracy:\t 0.925 test_loss:\t 0.012 test_accuracy:\t 0.878\n",
      "epoch:\t 7 loss:\t 0.008 accuracy:\t 0.919 test_loss:\t 0.013 test_accuracy:\t 0.859\n",
      "epoch:\t 8 loss:\t 0.008 accuracy:\t 0.913 test_loss:\t 0.011 test_accuracy:\t 0.872\n",
      "epoch:\t 9 loss:\t 0.008 accuracy:\t 0.916 test_loss:\t 0.012 test_accuracy:\t 0.86\n",
      "epoch:\t 10 loss:\t 0.009 accuracy:\t 0.904 test_loss:\t 0.013 test_accuracy:\t 0.869\n",
      "epoch:\t 11 loss:\t 0.009 accuracy:\t 0.902 test_loss:\t 0.014 test_accuracy:\t 0.797\n",
      "epoch:\t 12 loss:\t 0.01 accuracy:\t 0.885 test_loss:\t 0.013 test_accuracy:\t 0.847\n",
      "epoch:\t 13 loss:\t 0.011 accuracy:\t 0.877 test_loss:\t 0.013 test_accuracy:\t 0.858\n",
      "epoch:\t 14 loss:\t 0.011 accuracy:\t 0.874 test_loss:\t 0.014 test_accuracy:\t 0.834\n",
      "epoch:\t 15 loss:\t 0.011 accuracy:\t 0.871 test_loss:\t 0.015 test_accuracy:\t 0.84\n",
      "epoch:\t 16 loss:\t 0.011 accuracy:\t 0.858 test_loss:\t 0.014 test_accuracy:\t 0.823\n",
      "epoch:\t 17 loss:\t 0.012 accuracy:\t 0.843 test_loss:\t 0.015 test_accuracy:\t 0.827\n",
      "epoch:\t 18 loss:\t 0.012 accuracy:\t 0.843 test_loss:\t 0.017 test_accuracy:\t 0.828\n",
      "epoch:\t 19 loss:\t 0.012 accuracy:\t 0.844 test_loss:\t 0.015 test_accuracy:\t 0.821\n",
      "epoch:\t 20 loss:\t 0.012 accuracy:\t 0.841 test_loss:\t 0.015 test_accuracy:\t 0.778\n",
      "epoch:\t 21 loss:\t 0.013 accuracy:\t 0.828 test_loss:\t 0.015 test_accuracy:\t 0.832\n",
      "epoch:\t 22 loss:\t 0.013 accuracy:\t 0.832 test_loss:\t 0.014 test_accuracy:\t 0.807\n",
      "epoch:\t 23 loss:\t 0.013 accuracy:\t 0.829 test_loss:\t 0.015 test_accuracy:\t 0.819\n",
      "epoch:\t 24 loss:\t 0.012 accuracy:\t 0.84 test_loss:\t 0.018 test_accuracy:\t 0.759\n",
      "epoch:\t 25 loss:\t 0.012 accuracy:\t 0.836 test_loss:\t 0.014 test_accuracy:\t 0.8\n",
      "epoch:\t 26 loss:\t 0.013 accuracy:\t 0.833 test_loss:\t 0.016 test_accuracy:\t 0.774\n",
      "epoch:\t 27 loss:\t 0.013 accuracy:\t 0.831 test_loss:\t 0.015 test_accuracy:\t 0.807\n",
      "epoch:\t 28 loss:\t 0.013 accuracy:\t 0.828 test_loss:\t 0.014 test_accuracy:\t 0.812\n",
      "epoch:\t 29 loss:\t 0.013 accuracy:\t 0.816 test_loss:\t 0.015 test_accuracy:\t 0.805\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, epoch_test_loss, epoch_test_acc = fit(epoch,model,train_dl,test_dl)\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_acc.append(epoch_acc)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    test_acc.append(epoch_test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
