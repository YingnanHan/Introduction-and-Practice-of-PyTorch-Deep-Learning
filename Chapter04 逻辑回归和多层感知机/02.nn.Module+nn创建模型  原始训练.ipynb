{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f77d239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd0a2d",
   "metadata": {},
   "source": [
    "##### 处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d08013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset/HR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab0603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(pd.get_dummies(data.salary))\n",
    "del data['salary']\n",
    "data = data.join(pd.get_dummies(data.part))\n",
    "del data['part']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8bb5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data[[c for c in data.columns if c != 'left']].values\n",
    "X      = torch.from_numpy(X_data).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11775e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = data[[c for c in data.columns if c == 'left']].values\n",
    "Y      = torch.from_numpy(Y_data).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6779ae94",
   "metadata": {},
   "source": [
    "##### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "837d0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "396208c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(20,64)\n",
    "        self.linear_2 = nn.Linear(64,64)\n",
    "        self.linear_3 = nn.Linear(64,1)\n",
    "        self.relu     = nn.ReLU()\n",
    "        self.sigmoid  = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,input):\n",
    "        x = self.linear_1(input)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee3ed84",
   "metadata": {},
   "source": [
    "##### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5087555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Model()\n",
    "    opt   = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    return model,opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c0895fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,optim        = get_model()\n",
    "loss_fn            = nn.BCELoss()\n",
    "\n",
    "batch_size         = 64\n",
    "numnber_of_batches = len(data)//batch_size\n",
    "epoches            = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "815526c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:\t 0 \t\t\t loss:\t 0.6028925776481628\n",
      "epoch:\t 1 \t\t\t loss:\t 0.6054073572158813\n",
      "epoch:\t 2 \t\t\t loss:\t 0.6053191423416138\n",
      "epoch:\t 3 \t\t\t loss:\t 0.6011462807655334\n",
      "epoch:\t 4 \t\t\t loss:\t 0.5955274701118469\n",
      "epoch:\t 5 \t\t\t loss:\t 0.5895217061042786\n",
      "epoch:\t 6 \t\t\t loss:\t 0.5837771892547607\n",
      "epoch:\t 7 \t\t\t loss:\t 0.5786375403404236\n",
      "epoch:\t 8 \t\t\t loss:\t 0.5741863250732422\n",
      "epoch:\t 9 \t\t\t loss:\t 0.5705020427703857\n",
      "epoch:\t 10 \t\t\t loss:\t 0.5675674676895142\n",
      "epoch:\t 11 \t\t\t loss:\t 0.5652454495429993\n",
      "epoch:\t 12 \t\t\t loss:\t 0.5636212825775146\n",
      "epoch:\t 13 \t\t\t loss:\t 0.5628132820129395\n",
      "epoch:\t 14 \t\t\t loss:\t 0.5624322295188904\n",
      "epoch:\t 15 \t\t\t loss:\t 0.5627555251121521\n",
      "epoch:\t 16 \t\t\t loss:\t 0.5668768286705017\n",
      "epoch:\t 17 \t\t\t loss:\t 0.5667158961296082\n",
      "epoch:\t 18 \t\t\t loss:\t 0.5668954849243164\n",
      "epoch:\t 19 \t\t\t loss:\t 0.5671303272247314\n",
      "epoch:\t 20 \t\t\t loss:\t 0.5672408938407898\n",
      "epoch:\t 21 \t\t\t loss:\t 0.5674843788146973\n",
      "epoch:\t 22 \t\t\t loss:\t 0.5675179362297058\n",
      "epoch:\t 23 \t\t\t loss:\t 0.5674824118614197\n",
      "epoch:\t 24 \t\t\t loss:\t 0.5676258206367493\n",
      "epoch:\t 25 \t\t\t loss:\t 0.5674365758895874\n",
      "epoch:\t 26 \t\t\t loss:\t 0.5664278268814087\n",
      "epoch:\t 27 \t\t\t loss:\t 0.5673649907112122\n",
      "epoch:\t 28 \t\t\t loss:\t 0.5675670504570007\n",
      "epoch:\t 29 \t\t\t loss:\t 0.5674617290496826\n",
      "epoch:\t 30 \t\t\t loss:\t 0.5674002766609192\n",
      "epoch:\t 31 \t\t\t loss:\t 0.5668933391571045\n",
      "epoch:\t 32 \t\t\t loss:\t 0.566629946231842\n",
      "epoch:\t 33 \t\t\t loss:\t 0.565361738204956\n",
      "epoch:\t 34 \t\t\t loss:\t 0.5660302639007568\n",
      "epoch:\t 35 \t\t\t loss:\t 0.5658069252967834\n",
      "epoch:\t 36 \t\t\t loss:\t 0.565554678440094\n",
      "epoch:\t 37 \t\t\t loss:\t 0.5703665614128113\n",
      "epoch:\t 38 \t\t\t loss:\t 0.5649846196174622\n",
      "epoch:\t 39 \t\t\t loss:\t 0.564320981502533\n",
      "epoch:\t 40 \t\t\t loss:\t 0.5640623569488525\n",
      "epoch:\t 41 \t\t\t loss:\t 0.5632966756820679\n",
      "epoch:\t 42 \t\t\t loss:\t 0.5633145570755005\n",
      "epoch:\t 43 \t\t\t loss:\t 0.5632198452949524\n",
      "epoch:\t 44 \t\t\t loss:\t 0.5626670718193054\n",
      "epoch:\t 45 \t\t\t loss:\t 0.5621350407600403\n",
      "epoch:\t 46 \t\t\t loss:\t 0.5737219452857971\n",
      "epoch:\t 47 \t\t\t loss:\t 0.5618299245834351\n",
      "epoch:\t 48 \t\t\t loss:\t 0.5613285899162292\n",
      "epoch:\t 49 \t\t\t loss:\t 0.5611511468887329\n",
      "epoch:\t 50 \t\t\t loss:\t 0.5610030293464661\n",
      "epoch:\t 51 \t\t\t loss:\t 0.560424268245697\n",
      "epoch:\t 52 \t\t\t loss:\t 0.5605891346931458\n",
      "epoch:\t 53 \t\t\t loss:\t 0.5594221353530884\n",
      "epoch:\t 54 \t\t\t loss:\t 0.5600503087043762\n",
      "epoch:\t 55 \t\t\t loss:\t 0.559517502784729\n",
      "epoch:\t 56 \t\t\t loss:\t 0.5558733940124512\n",
      "epoch:\t 57 \t\t\t loss:\t 0.5595362186431885\n",
      "epoch:\t 58 \t\t\t loss:\t 0.5592405796051025\n",
      "epoch:\t 59 \t\t\t loss:\t 0.5575810074806213\n",
      "epoch:\t 60 \t\t\t loss:\t 0.5589228272438049\n",
      "epoch:\t 61 \t\t\t loss:\t 0.5575658082962036\n",
      "epoch:\t 62 \t\t\t loss:\t 0.5627334713935852\n",
      "epoch:\t 63 \t\t\t loss:\t 0.5540049076080322\n",
      "epoch:\t 64 \t\t\t loss:\t 0.6163487434387207\n",
      "epoch:\t 65 \t\t\t loss:\t 0.6472000479698181\n",
      "epoch:\t 66 \t\t\t loss:\t 0.5944804549217224\n",
      "epoch:\t 67 \t\t\t loss:\t 0.5613621473312378\n",
      "epoch:\t 68 \t\t\t loss:\t 0.5632069110870361\n",
      "epoch:\t 69 \t\t\t loss:\t 0.5618670582771301\n",
      "epoch:\t 70 \t\t\t loss:\t 0.5607610940933228\n",
      "epoch:\t 71 \t\t\t loss:\t 0.5796818733215332\n",
      "epoch:\t 72 \t\t\t loss:\t 0.5674793124198914\n",
      "epoch:\t 73 \t\t\t loss:\t 0.5593148469924927\n",
      "epoch:\t 74 \t\t\t loss:\t 0.5522340536117554\n",
      "epoch:\t 75 \t\t\t loss:\t 0.5567151308059692\n",
      "epoch:\t 76 \t\t\t loss:\t 0.5515447854995728\n",
      "epoch:\t 77 \t\t\t loss:\t 0.551618754863739\n",
      "epoch:\t 78 \t\t\t loss:\t 0.5518413186073303\n",
      "epoch:\t 79 \t\t\t loss:\t 0.549130916595459\n",
      "epoch:\t 80 \t\t\t loss:\t 0.5482041835784912\n",
      "epoch:\t 81 \t\t\t loss:\t 0.5483935475349426\n",
      "epoch:\t 82 \t\t\t loss:\t 0.5575568079948425\n",
      "epoch:\t 83 \t\t\t loss:\t 0.5492405295372009\n",
      "epoch:\t 84 \t\t\t loss:\t 0.5469751358032227\n",
      "epoch:\t 85 \t\t\t loss:\t 0.5383028984069824\n",
      "epoch:\t 86 \t\t\t loss:\t 0.5427020788192749\n",
      "epoch:\t 87 \t\t\t loss:\t 0.5436234474182129\n",
      "epoch:\t 88 \t\t\t loss:\t 0.5429636836051941\n",
      "epoch:\t 89 \t\t\t loss:\t 0.5430029034614563\n",
      "epoch:\t 90 \t\t\t loss:\t 0.5407467484474182\n",
      "epoch:\t 91 \t\t\t loss:\t 0.540006697177887\n",
      "epoch:\t 92 \t\t\t loss:\t 0.5392387509346008\n",
      "epoch:\t 93 \t\t\t loss:\t 0.5395568013191223\n",
      "epoch:\t 94 \t\t\t loss:\t 0.5499719977378845\n",
      "epoch:\t 95 \t\t\t loss:\t 0.5365390777587891\n",
      "epoch:\t 96 \t\t\t loss:\t 0.5328450202941895\n",
      "epoch:\t 97 \t\t\t loss:\t 0.534371554851532\n",
      "epoch:\t 98 \t\t\t loss:\t 0.5311505794525146\n",
      "epoch:\t 99 \t\t\t loss:\t 0.5328046083450317\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoches):\n",
    "    for i in range(numnber_of_batches):\n",
    "        start = i*batch_size\n",
    "        end   = i*batch_size + batch_size\n",
    "        x     = X[start:end]\n",
    "        y     = Y[start:end]\n",
    "        y_pred= model(x)\n",
    "        loss  = loss_fn(y_pred,y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        loss_fn(model(X),Y)\n",
    "        print(\"epoch:\\t\",epoch,\"\\t\\t\\t\",\"loss:\\t\",loss_fn(model(X),Y).data.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
