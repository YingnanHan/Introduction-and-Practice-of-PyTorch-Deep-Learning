{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da883f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb25965",
   "metadata": {},
   "source": [
    "##### 处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78c7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./dataset/HR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c89d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(pd.get_dummies(data.salary))\n",
    "del  data[\"salary\"]\n",
    "data = data.join(pd.get_dummies(data.part))\n",
    "del  data[\"part\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3bb09da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data[[c for c in data.columns if c != 'left']].values\n",
    "X      = torch.from_numpy(X_data).type(torch.FloatTensor)\n",
    "Y_data = data[[c for c in data.columns if c == 'left']].values\n",
    "Y      = torch.from_numpy(Y_data).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c69f72f",
   "metadata": {},
   "source": [
    "##### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34956b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f20f2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(20,64)\n",
    "        self.linear_2 = nn.Linear(64,64)\n",
    "        self.linear_3 = nn.Linear(64,1)\n",
    "    \n",
    "    def forward(self,input):\n",
    "        x = self.linear_1(input)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear_3(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdb7784",
   "metadata": {},
   "source": [
    "##### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f1a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Model()\n",
    "    opt   =torch.optim.Adam(model.parameters(),lr = 0.0001)\n",
    "    return model,opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eef5b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,optim      = get_model()\n",
    "loss_fn          = nn.BCELoss()\n",
    "\n",
    "batch_size       = 64\n",
    "number_of_batches= len(data)//batch_size\n",
    "epoches          = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b21ad2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09250580",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_dataset = TensorDataset(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8a0f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \t\t\t loss: 0.7488163113594055\n",
      "epoch: 1 \t\t\t loss: 0.764328122138977\n",
      "epoch: 2 \t\t\t loss: 0.7634185552597046\n",
      "epoch: 3 \t\t\t loss: 0.7626663446426392\n",
      "epoch: 4 \t\t\t loss: 0.7669923305511475\n",
      "epoch: 5 \t\t\t loss: 0.7576279044151306\n",
      "epoch: 6 \t\t\t loss: 0.7532246112823486\n",
      "epoch: 7 \t\t\t loss: 0.7481994032859802\n",
      "epoch: 8 \t\t\t loss: 0.742649257183075\n",
      "epoch: 9 \t\t\t loss: 0.7525537014007568\n",
      "epoch: 10 \t\t\t loss: 0.7347663640975952\n",
      "epoch: 11 \t\t\t loss: 0.7252159118652344\n",
      "epoch: 12 \t\t\t loss: 0.7150465250015259\n",
      "epoch: 13 \t\t\t loss: 0.7064523696899414\n",
      "epoch: 14 \t\t\t loss: 0.6980971693992615\n",
      "epoch: 15 \t\t\t loss: 0.6890510320663452\n",
      "epoch: 16 \t\t\t loss: 0.6804039478302002\n",
      "epoch: 17 \t\t\t loss: 0.6714966297149658\n",
      "epoch: 18 \t\t\t loss: 0.6626542210578918\n",
      "epoch: 19 \t\t\t loss: 0.652764081954956\n",
      "epoch: 20 \t\t\t loss: 0.6410772204399109\n",
      "epoch: 21 \t\t\t loss: 0.6316114664077759\n",
      "epoch: 22 \t\t\t loss: 0.6222035884857178\n",
      "epoch: 23 \t\t\t loss: 0.6014999151229858\n",
      "epoch: 24 \t\t\t loss: 0.5938387513160706\n",
      "epoch: 25 \t\t\t loss: 0.5872128009796143\n",
      "epoch: 26 \t\t\t loss: 0.5812497138977051\n",
      "epoch: 27 \t\t\t loss: 0.5793298482894897\n",
      "epoch: 28 \t\t\t loss: 0.5791695713996887\n",
      "epoch: 29 \t\t\t loss: 0.5725651383399963\n",
      "epoch: 30 \t\t\t loss: 0.5678300857543945\n",
      "epoch: 31 \t\t\t loss: 0.5641459226608276\n",
      "epoch: 32 \t\t\t loss: 0.561199963092804\n",
      "epoch: 33 \t\t\t loss: 0.5593439340591431\n",
      "epoch: 34 \t\t\t loss: 0.5572348237037659\n",
      "epoch: 35 \t\t\t loss: 0.5560996532440186\n",
      "epoch: 36 \t\t\t loss: 0.5553497076034546\n",
      "epoch: 37 \t\t\t loss: 0.5549736618995667\n",
      "epoch: 38 \t\t\t loss: 0.5547928214073181\n",
      "epoch: 39 \t\t\t loss: 0.5549175143241882\n",
      "epoch: 40 \t\t\t loss: 0.5556364059448242\n",
      "epoch: 41 \t\t\t loss: 0.5565494894981384\n",
      "epoch: 42 \t\t\t loss: 0.5568755865097046\n",
      "epoch: 43 \t\t\t loss: 0.5575598478317261\n",
      "epoch: 44 \t\t\t loss: 0.5595230460166931\n",
      "epoch: 45 \t\t\t loss: 0.5598379373550415\n",
      "epoch: 46 \t\t\t loss: 0.5600266456604004\n",
      "epoch: 47 \t\t\t loss: 0.5605303645133972\n",
      "epoch: 48 \t\t\t loss: 0.56036376953125\n",
      "epoch: 49 \t\t\t loss: 0.565105140209198\n",
      "epoch: 50 \t\t\t loss: 0.5837451219558716\n",
      "epoch: 51 \t\t\t loss: 0.562288761138916\n",
      "epoch: 52 \t\t\t loss: 0.561517059803009\n",
      "epoch: 53 \t\t\t loss: 0.56109219789505\n",
      "epoch: 54 \t\t\t loss: 0.5611411333084106\n",
      "epoch: 55 \t\t\t loss: 0.5607362985610962\n",
      "epoch: 56 \t\t\t loss: 0.5598210692405701\n",
      "epoch: 57 \t\t\t loss: 0.5601159930229187\n",
      "epoch: 58 \t\t\t loss: 0.5781550407409668\n",
      "epoch: 59 \t\t\t loss: 0.5585865378379822\n",
      "epoch: 60 \t\t\t loss: 0.5582656860351562\n",
      "epoch: 61 \t\t\t loss: 0.5776510834693909\n",
      "epoch: 62 \t\t\t loss: 0.5536653399467468\n",
      "epoch: 63 \t\t\t loss: 0.5714534521102905\n",
      "epoch: 64 \t\t\t loss: 0.5545243620872498\n",
      "epoch: 65 \t\t\t loss: 0.5548143982887268\n",
      "epoch: 66 \t\t\t loss: 0.5711240768432617\n",
      "epoch: 67 \t\t\t loss: 0.552689254283905\n",
      "epoch: 68 \t\t\t loss: 0.5631875991821289\n",
      "epoch: 69 \t\t\t loss: 0.5507674217224121\n",
      "epoch: 70 \t\t\t loss: 0.5536529421806335\n",
      "epoch: 71 \t\t\t loss: 0.5510859489440918\n",
      "epoch: 72 \t\t\t loss: 0.5535743236541748\n",
      "epoch: 73 \t\t\t loss: 0.5520777106285095\n",
      "epoch: 74 \t\t\t loss: 0.5517135262489319\n",
      "epoch: 75 \t\t\t loss: 0.5492249131202698\n",
      "epoch: 76 \t\t\t loss: 0.5501536130905151\n",
      "epoch: 77 \t\t\t loss: 0.5483585596084595\n",
      "epoch: 78 \t\t\t loss: 0.5489203929901123\n",
      "epoch: 79 \t\t\t loss: 0.5555292963981628\n",
      "epoch: 80 \t\t\t loss: 0.5646666288375854\n",
      "epoch: 81 \t\t\t loss: 0.5470735430717468\n",
      "epoch: 82 \t\t\t loss: 0.5448102355003357\n",
      "epoch: 83 \t\t\t loss: 0.5442879796028137\n",
      "epoch: 84 \t\t\t loss: 0.5449665188789368\n",
      "epoch: 85 \t\t\t loss: 0.5420778393745422\n",
      "epoch: 86 \t\t\t loss: 0.5422638654708862\n",
      "epoch: 87 \t\t\t loss: 0.5411716103553772\n",
      "epoch: 88 \t\t\t loss: 0.5385682582855225\n",
      "epoch: 89 \t\t\t loss: 0.5398218035697937\n",
      "epoch: 90 \t\t\t loss: 0.5371127724647522\n",
      "epoch: 91 \t\t\t loss: 0.5386224389076233\n",
      "epoch: 92 \t\t\t loss: 0.5719046592712402\n",
      "epoch: 93 \t\t\t loss: 0.5403630137443542\n",
      "epoch: 94 \t\t\t loss: 0.5358414649963379\n",
      "epoch: 95 \t\t\t loss: 0.5321618318557739\n",
      "epoch: 96 \t\t\t loss: 0.533842921257019\n",
      "epoch: 97 \t\t\t loss: 0.5297894477844238\n",
      "epoch: 98 \t\t\t loss: 0.5315873026847839\n",
      "epoch: 99 \t\t\t loss: 0.528934895992279\n"
     ]
    }
   ],
   "source": [
    "for epoche in range(epoches):\n",
    "    for i in range(number_of_batches):\n",
    "        x,y     = HR_dataset[i*batch_size:i*batch_size+batch_size]\n",
    "        y_pred  = model(x)\n",
    "        loss    = loss_fn(y_pred,y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        print(\"epoch:\",epoche,\"\\t\\t\\t\",\"loss:\",loss_fn(model(X),Y).data.item())   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
