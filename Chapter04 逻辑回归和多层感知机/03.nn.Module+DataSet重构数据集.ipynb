{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816d3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4055e",
   "metadata": {},
   "source": [
    "##### 处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e25411",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset/HR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf13903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(pd.get_dummies(data.salary))\n",
    "del  data['salary']\n",
    "data = data.join(pd.get_dummies(data.part))\n",
    "del  data['part']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff83336",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data[[c for c in data.columns if c != 'left']].values\n",
    "X      = torch.from_numpy(X_data).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e712403",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = data[[c for c in data.columns if c == 'left']].values\n",
    "Y      = torch.from_numpy(Y_data).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bdf6cb",
   "metadata": {},
   "source": [
    "##### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16450404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d36f70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(20,64)\n",
    "        self.linear_2 = nn.Linear(64,64)\n",
    "        self.linear_3 = nn.Linear(64,1)\n",
    "        self.relu     = nn.ReLU()\n",
    "        self.sigmoid  = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,input):\n",
    "        x = self.linear_1(input)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d7360b",
   "metadata": {},
   "source": [
    "##### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6a5c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Model()\n",
    "    opt   = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    return model,opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eccbbe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,optim      = get_model()\n",
    "loss_fn          = nn.BCELoss()\n",
    "\n",
    "batch_size       = 64\n",
    "number_of_batches= len(data)//batch_size\n",
    "epochs           = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d344758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b31328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HRdataset = TensorDataset(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "924e6199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \t\t\t loss: 0.7335248589515686\n",
      "epoch: 1 \t\t\t loss: 0.7064924240112305\n",
      "epoch: 2 \t\t\t loss: 0.6973234415054321\n",
      "epoch: 3 \t\t\t loss: 0.6871408820152283\n",
      "epoch: 4 \t\t\t loss: 0.6662421226501465\n",
      "epoch: 5 \t\t\t loss: 0.6511802077293396\n",
      "epoch: 6 \t\t\t loss: 0.6426291465759277\n",
      "epoch: 7 \t\t\t loss: 0.6867966055870056\n",
      "epoch: 8 \t\t\t loss: 0.6579023003578186\n",
      "epoch: 9 \t\t\t loss: 0.6410834193229675\n",
      "epoch: 10 \t\t\t loss: 0.6280080080032349\n",
      "epoch: 11 \t\t\t loss: 0.6102624535560608\n",
      "epoch: 12 \t\t\t loss: 0.6004673838615417\n",
      "epoch: 13 \t\t\t loss: 0.592176616191864\n",
      "epoch: 14 \t\t\t loss: 0.5910249948501587\n",
      "epoch: 15 \t\t\t loss: 0.5791337490081787\n",
      "epoch: 16 \t\t\t loss: 0.5749177932739258\n",
      "epoch: 17 \t\t\t loss: 0.5698032975196838\n",
      "epoch: 18 \t\t\t loss: 0.566704273223877\n",
      "epoch: 19 \t\t\t loss: 0.5640634894371033\n",
      "epoch: 20 \t\t\t loss: 0.5621867179870605\n",
      "epoch: 21 \t\t\t loss: 0.5609436631202698\n",
      "epoch: 22 \t\t\t loss: 0.5601813197135925\n",
      "epoch: 23 \t\t\t loss: 0.5597779154777527\n",
      "epoch: 24 \t\t\t loss: 0.5640770792961121\n",
      "epoch: 25 \t\t\t loss: 0.5602397322654724\n",
      "epoch: 26 \t\t\t loss: 0.5593632459640503\n",
      "epoch: 27 \t\t\t loss: 0.5596374273300171\n",
      "epoch: 28 \t\t\t loss: 0.5601159334182739\n",
      "epoch: 29 \t\t\t loss: 0.5603232383728027\n",
      "epoch: 30 \t\t\t loss: 0.5607693791389465\n",
      "epoch: 31 \t\t\t loss: 0.561142086982727\n",
      "epoch: 32 \t\t\t loss: 0.5596095323562622\n",
      "epoch: 33 \t\t\t loss: 0.5574869513511658\n",
      "epoch: 34 \t\t\t loss: 0.5615817904472351\n",
      "epoch: 35 \t\t\t loss: 0.5608192086219788\n",
      "epoch: 36 \t\t\t loss: 0.562149703502655\n",
      "epoch: 37 \t\t\t loss: 0.5618387460708618\n",
      "epoch: 38 \t\t\t loss: 0.5622093677520752\n",
      "epoch: 39 \t\t\t loss: 0.5616997480392456\n",
      "epoch: 40 \t\t\t loss: 0.5617772936820984\n",
      "epoch: 41 \t\t\t loss: 0.5617229342460632\n",
      "epoch: 42 \t\t\t loss: 0.5603634119033813\n",
      "epoch: 43 \t\t\t loss: 0.5611504316329956\n",
      "epoch: 44 \t\t\t loss: 0.5582305192947388\n",
      "epoch: 45 \t\t\t loss: 0.560596227645874\n",
      "epoch: 46 \t\t\t loss: 0.5592881441116333\n",
      "epoch: 47 \t\t\t loss: 0.5554000735282898\n",
      "epoch: 48 \t\t\t loss: 0.5642790198326111\n",
      "epoch: 49 \t\t\t loss: 0.5606086254119873\n",
      "epoch: 50 \t\t\t loss: 0.5592835545539856\n",
      "epoch: 51 \t\t\t loss: 0.5589659214019775\n",
      "epoch: 52 \t\t\t loss: 0.558722198009491\n",
      "epoch: 53 \t\t\t loss: 0.5583982467651367\n",
      "epoch: 54 \t\t\t loss: 0.5580925345420837\n",
      "epoch: 55 \t\t\t loss: 0.5578041076660156\n",
      "epoch: 56 \t\t\t loss: 0.5569249987602234\n",
      "epoch: 57 \t\t\t loss: 0.5551437735557556\n",
      "epoch: 58 \t\t\t loss: 0.5541048645973206\n",
      "epoch: 59 \t\t\t loss: 0.5557698607444763\n",
      "epoch: 60 \t\t\t loss: 0.5565793514251709\n",
      "epoch: 61 \t\t\t loss: 0.5556983947753906\n",
      "epoch: 62 \t\t\t loss: 0.5564566254615784\n",
      "epoch: 63 \t\t\t loss: 0.55604487657547\n",
      "epoch: 64 \t\t\t loss: 0.5555897355079651\n",
      "epoch: 65 \t\t\t loss: 0.5540205836296082\n",
      "epoch: 66 \t\t\t loss: 0.5544052124023438\n",
      "epoch: 67 \t\t\t loss: 0.5548162460327148\n",
      "epoch: 68 \t\t\t loss: 0.5551663041114807\n",
      "epoch: 69 \t\t\t loss: 0.5544496178627014\n",
      "epoch: 70 \t\t\t loss: 0.5896532535552979\n",
      "epoch: 71 \t\t\t loss: 0.5643215775489807\n",
      "epoch: 72 \t\t\t loss: 0.5565565824508667\n",
      "epoch: 73 \t\t\t loss: 0.556458055973053\n",
      "epoch: 74 \t\t\t loss: 0.5495427846908569\n",
      "epoch: 75 \t\t\t loss: 0.5536558032035828\n",
      "epoch: 76 \t\t\t loss: 0.5499370098114014\n",
      "epoch: 77 \t\t\t loss: 0.5500331521034241\n",
      "epoch: 78 \t\t\t loss: 0.5492350459098816\n",
      "epoch: 79 \t\t\t loss: 0.5521761178970337\n",
      "epoch: 80 \t\t\t loss: 0.5922044515609741\n",
      "epoch: 81 \t\t\t loss: 0.5760235786437988\n",
      "epoch: 82 \t\t\t loss: 0.5534910559654236\n",
      "epoch: 83 \t\t\t loss: 0.5486920475959778\n",
      "epoch: 84 \t\t\t loss: 0.5411086082458496\n",
      "epoch: 85 \t\t\t loss: 0.5423884987831116\n",
      "epoch: 86 \t\t\t loss: 0.5455347895622253\n",
      "epoch: 87 \t\t\t loss: 0.5385317802429199\n",
      "epoch: 88 \t\t\t loss: 0.5371930599212646\n",
      "epoch: 89 \t\t\t loss: 0.5404536724090576\n",
      "epoch: 90 \t\t\t loss: 0.5398073792457581\n",
      "epoch: 91 \t\t\t loss: 0.5325711965560913\n",
      "epoch: 92 \t\t\t loss: 0.5364156365394592\n",
      "epoch: 93 \t\t\t loss: 0.5317083597183228\n",
      "epoch: 94 \t\t\t loss: 0.5390514731407166\n",
      "epoch: 95 \t\t\t loss: 0.5338767766952515\n",
      "epoch: 96 \t\t\t loss: 0.5342598557472229\n",
      "epoch: 97 \t\t\t loss: 0.5316320061683655\n",
      "epoch: 98 \t\t\t loss: 0.532954216003418\n",
      "epoch: 99 \t\t\t loss: 0.52903151512146\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(number_of_batches):\n",
    "        x,y    = HRdataset[i*batch_size:i*batch_size+batch_size]\n",
    "        y_pred = model(x)\n",
    "        loss   = loss_fn(y_pred,y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        print(\"epoch:\",epoch,\"\\t\\t\\t\",\"loss:\",loss_fn(model(X),Y).data.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
