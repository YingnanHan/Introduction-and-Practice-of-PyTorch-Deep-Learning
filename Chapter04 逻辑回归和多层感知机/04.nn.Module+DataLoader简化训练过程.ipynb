{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "230f3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76589065",
   "metadata": {},
   "source": [
    "##### 处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56043846",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./dataset/HR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8e4bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(pd.get_dummies(data.salary))\n",
    "del  data['salary']\n",
    "data = data.join(pd.get_dummies(data.part))\n",
    "del  data['part']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b05f6980",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data[[c for c in data.columns if c != 'left']].values\n",
    "X      = torch.from_numpy(X_data).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6e41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = data[[c for c in data.columns if c == 'left']].values\n",
    "Y      = torch.from_numpy(Y_data).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59727ac",
   "metadata": {},
   "source": [
    "##### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ba7770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43256cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(20,64)\n",
    "        self.linear_2 = nn.Linear(64,64)\n",
    "        self.linear_3 = nn.Linear(64,1)\n",
    "        self.relu     = nn.ReLU()\n",
    "        self.sigmoid  = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,input):\n",
    "        x = self.linear_1(input)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.linear_3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ea709",
   "metadata": {},
   "source": [
    "##### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1190e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Model()\n",
    "    opt   = torch.optim.Adam(model.parameters(),lr = 0.0001)\n",
    "    return model,opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3c9db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,optim       = get_model()\n",
    "loss_fn           = nn.BCELoss()\n",
    "\n",
    "batch_size        = 64\n",
    "number_of_batches = len(data)//batch_size\n",
    "epochs            = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba734570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2a22636",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_ds = TensorDataset(X,Y)\n",
    "HR_dl = DataLoader(HR_ds,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e962b6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \t\t\t loss: 0.5523072481155396\n",
      "epoch: 1 \t\t\t loss: 0.5473362803459167\n",
      "epoch: 2 \t\t\t loss: 0.5459263324737549\n",
      "epoch: 3 \t\t\t loss: 0.5445169806480408\n",
      "epoch: 4 \t\t\t loss: 0.5430164337158203\n",
      "epoch: 5 \t\t\t loss: 0.5417057871818542\n",
      "epoch: 6 \t\t\t loss: 0.5395357012748718\n",
      "epoch: 7 \t\t\t loss: 0.5370337963104248\n",
      "epoch: 8 \t\t\t loss: 0.534522294998169\n",
      "epoch: 9 \t\t\t loss: 0.5311946272850037\n",
      "epoch: 10 \t\t\t loss: 0.5276020765304565\n",
      "epoch: 11 \t\t\t loss: 0.5228965282440186\n",
      "epoch: 12 \t\t\t loss: 0.5178536772727966\n",
      "epoch: 13 \t\t\t loss: 0.5121708512306213\n",
      "epoch: 14 \t\t\t loss: 0.5064887404441833\n",
      "epoch: 15 \t\t\t loss: 0.5004053115844727\n",
      "epoch: 16 \t\t\t loss: 0.49338042736053467\n",
      "epoch: 17 \t\t\t loss: 0.48758363723754883\n",
      "epoch: 18 \t\t\t loss: 0.4793899655342102\n",
      "epoch: 19 \t\t\t loss: 0.4726359248161316\n",
      "epoch: 20 \t\t\t loss: 0.46746352314949036\n",
      "epoch: 21 \t\t\t loss: 0.46468937397003174\n",
      "epoch: 22 \t\t\t loss: 0.45422399044036865\n",
      "epoch: 23 \t\t\t loss: 0.44976183772087097\n",
      "epoch: 24 \t\t\t loss: 0.4440445899963379\n",
      "epoch: 25 \t\t\t loss: 0.43965262174606323\n",
      "epoch: 26 \t\t\t loss: 0.4349934458732605\n",
      "epoch: 27 \t\t\t loss: 0.430885374546051\n",
      "epoch: 28 \t\t\t loss: 0.4258594512939453\n",
      "epoch: 29 \t\t\t loss: 0.42235371470451355\n",
      "epoch: 30 \t\t\t loss: 0.41837644577026367\n",
      "epoch: 31 \t\t\t loss: 0.41367200016975403\n",
      "epoch: 32 \t\t\t loss: 0.40893954038619995\n",
      "epoch: 33 \t\t\t loss: 0.40694159269332886\n",
      "epoch: 34 \t\t\t loss: 0.401122123003006\n",
      "epoch: 35 \t\t\t loss: 0.39799246191978455\n",
      "epoch: 36 \t\t\t loss: 0.393269419670105\n",
      "epoch: 37 \t\t\t loss: 0.3896885812282562\n",
      "epoch: 38 \t\t\t loss: 0.38644859194755554\n",
      "epoch: 39 \t\t\t loss: 0.38289594650268555\n",
      "epoch: 40 \t\t\t loss: 0.3797178566455841\n",
      "epoch: 41 \t\t\t loss: 0.37859800457954407\n",
      "epoch: 42 \t\t\t loss: 0.3734552264213562\n",
      "epoch: 43 \t\t\t loss: 0.37097474932670593\n",
      "epoch: 44 \t\t\t loss: 0.36858323216438293\n",
      "epoch: 45 \t\t\t loss: 0.3667333722114563\n",
      "epoch: 46 \t\t\t loss: 0.3623476028442383\n",
      "epoch: 47 \t\t\t loss: 0.35916951298713684\n",
      "epoch: 48 \t\t\t loss: 0.3567887544631958\n",
      "epoch: 49 \t\t\t loss: 0.35500964522361755\n",
      "epoch: 50 \t\t\t loss: 0.35435423254966736\n",
      "epoch: 51 \t\t\t loss: 0.3497570753097534\n",
      "epoch: 52 \t\t\t loss: 0.3475261628627777\n",
      "epoch: 53 \t\t\t loss: 0.3448973298072815\n",
      "epoch: 54 \t\t\t loss: 0.34319519996643066\n",
      "epoch: 55 \t\t\t loss: 0.3408929109573364\n",
      "epoch: 56 \t\t\t loss: 0.338498055934906\n",
      "epoch: 57 \t\t\t loss: 0.3369469940662384\n",
      "epoch: 58 \t\t\t loss: 0.33518803119659424\n",
      "epoch: 59 \t\t\t loss: 0.3343566954135895\n",
      "epoch: 60 \t\t\t loss: 0.3303896486759186\n",
      "epoch: 61 \t\t\t loss: 0.330523282289505\n",
      "epoch: 62 \t\t\t loss: 0.32685938477516174\n",
      "epoch: 63 \t\t\t loss: 0.3251851797103882\n",
      "epoch: 64 \t\t\t loss: 0.32368749380111694\n",
      "epoch: 65 \t\t\t loss: 0.32193973660469055\n",
      "epoch: 66 \t\t\t loss: 0.32023170590400696\n",
      "epoch: 67 \t\t\t loss: 0.3206692934036255\n",
      "epoch: 68 \t\t\t loss: 0.31789568066596985\n",
      "epoch: 69 \t\t\t loss: 0.31729432940483093\n",
      "epoch: 70 \t\t\t loss: 0.31596606969833374\n",
      "epoch: 71 \t\t\t loss: 0.31413254141807556\n",
      "epoch: 72 \t\t\t loss: 0.31281259655952454\n",
      "epoch: 73 \t\t\t loss: 0.3108663260936737\n",
      "epoch: 74 \t\t\t loss: 0.30970945954322815\n",
      "epoch: 75 \t\t\t loss: 0.30936098098754883\n",
      "epoch: 76 \t\t\t loss: 0.3073965907096863\n",
      "epoch: 77 \t\t\t loss: 0.3069934546947479\n",
      "epoch: 78 \t\t\t loss: 0.3113524615764618\n",
      "epoch: 79 \t\t\t loss: 0.3042728006839752\n",
      "epoch: 80 \t\t\t loss: 0.30339908599853516\n",
      "epoch: 81 \t\t\t loss: 0.3046678900718689\n",
      "epoch: 82 \t\t\t loss: 0.3011937141418457\n",
      "epoch: 83 \t\t\t loss: 0.3022499084472656\n",
      "epoch: 84 \t\t\t loss: 0.29976797103881836\n",
      "epoch: 85 \t\t\t loss: 0.2997671663761139\n",
      "epoch: 86 \t\t\t loss: 0.2988874316215515\n",
      "epoch: 87 \t\t\t loss: 0.2966325283050537\n",
      "epoch: 88 \t\t\t loss: 0.29521632194519043\n",
      "epoch: 89 \t\t\t loss: 0.294533371925354\n",
      "epoch: 90 \t\t\t loss: 0.2950495183467865\n",
      "epoch: 91 \t\t\t loss: 0.2930915653705597\n",
      "epoch: 92 \t\t\t loss: 0.29330727458000183\n",
      "epoch: 93 \t\t\t loss: 0.29187506437301636\n",
      "epoch: 94 \t\t\t loss: 0.28944388031959534\n",
      "epoch: 95 \t\t\t loss: 0.2899511456489563\n",
      "epoch: 96 \t\t\t loss: 0.2877192497253418\n",
      "epoch: 97 \t\t\t loss: 0.29042503237724304\n",
      "epoch: 98 \t\t\t loss: 0.28611093759536743\n",
      "epoch: 99 \t\t\t loss: 0.28513669967651367\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x,y in HR_dl:\n",
    "        y_pred = model(x)\n",
    "        loss   = loss_fn(y_pred,y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        print(\"epoch:\",epoch,\"\\t\\t\\t\",\"loss:\",loss_fn(model(X),Y).data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffeb1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
